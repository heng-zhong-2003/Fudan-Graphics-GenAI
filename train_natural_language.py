#!/usr/bin/env python3  
"""  
ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œæ¤…å­è®¾è®¡å¾®è°ƒ  
"""  

import os  
import sys  
import json  
import torch  
from transformers import AutoTokenizer, AutoModelForCausalLM  
import gc  

def load_chair_data_natural():  
    """åŠ è½½æ¤…å­æ•°æ®å¹¶è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æ ¼å¼"""  
    print("ğŸ“Š åŠ è½½æ¤…å­æ•°æ®ï¼ˆè‡ªç„¶è¯­è¨€ç‰ˆæœ¬ï¼‰...")  
    
    data_dir = "./data_grouped"  
    chair_data = []  
    
    for folder_name in os.listdir(data_dir):  
        folder_path = os.path.join(data_dir, folder_name)  
        if not os.path.isdir(folder_path):  
            continue  
        
        txt_file = os.path.join(folder_path, f"{folder_name}.txt")  
        tags_file = os.path.join(folder_path, "tags.txt")  
        
        if os.path.exists(txt_file):  
            try:  
                # è¯»å–æ¤…å­æè¿°  
                with open(txt_file, 'r', encoding='utf-8') as f:  
                    description = f.read().strip()  
                
                # è¯»å–å¹¶è§£ææ ‡ç­¾  
                tags_dict = {}  
                if os.path.exists(tags_file):  
                    with open(tags_file, 'r', encoding='utf-8') as f:  
                        tags_content = f.read().strip()  
                        tags_dict = parse_tags_to_natural(tags_content)  
                
                # æ„é€ è‡ªç„¶è¯­è¨€æ ¼å¼  
                prompt = f"Design a chair: {description}"  
                
                # ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”  
                response = generate_natural_response(description, tags_dict)  
                
                chair_data.append((prompt, response))  
                print(f"  âœ… åŠ è½½æ¤…å­: {folder_name[:8]}...")  
                
            except Exception as e:  
                print(f"  âš ï¸ è·³è¿‡ {folder_name}: {e}")  
                continue  
    
    print(f"ğŸ“ˆ æ€»å…±åŠ è½½äº† {len(chair_data)} ä¸ªæ¤…å­æ ·æœ¬")  
    return chair_data  

def parse_tags_to_natural(tags_content):  
    """å°†æ ‡ç­¾è§£æä¸ºè‡ªç„¶è¯­è¨€å‹å¥½çš„å­—å…¸"""  
    tags_dict = {}  
    
    lines = tags_content.strip().split('\n')  
    for line in lines:  
        if ':' in line:  
            key, value = line.split(':', 1)  
            key = key.strip()  
            value = value.strip()  
            
            if value.lower() != 'null':  
                tags_dict[key] = value  
    
    return tags_dict  

def generate_natural_response(description, tags_dict):  
    """ç”Ÿæˆè‡ªç„¶è¯­è¨€çš„æ¤…å­è®¾è®¡å›ç­”"""  
    
    response_parts = []  
    
    # å¼€å§‹è®¾è®¡æè¿°  
    response_parts.append("I'll design this chair with the following features:")  
    
    # åŸºç¡€ç»“æ„  
    response_parts.append("\n**Structure:**")  
    response_parts.append("- Four legs for stability")  
    response_parts.append("- A horizontal seat surface")  
    response_parts.append("- A backrest for support")  
    
    # æ ¹æ®æ ‡ç­¾æ·»åŠ ç‰¹è‰²  
    style = tags_dict.get('ç°ä»£é£æ ¼', '')  
    if 'æç®€ä¸»ä¹‰' in style:  
        response_parts.append("\n**Style - Minimalist:**")  
        response_parts.append("- Clean, simple lines")  
        response_parts.append("- Thin, elegant proportions")  
        response_parts.append("- Minimal decorative elements")  
        response_parts.append("- Focus on functionality")  
    
    material = tags_dict.get('æè´¨ç›¸å…³æè¿°', '')  
    if 'å®æœ¨' in material:  
        response_parts.append("\n**Material - Solid Wood:**")  
        response_parts.append("- Natural wood construction")  
        response_parts.append("- Visible wood grain texture")  
        response_parts.append("- Warm, natural color")  
        response_parts.append("- Durable and sturdy build")  
    
    # åŠŸèƒ½ç‰¹æ€§  
    response_parts.append("\n**Functional Features:**")  
    
    ergonomic = tags_dict.get('äººä½“å·¥å­¦ç¬¦åˆæ€§', '').lower()  
    if ergonomic and ergonomic != 'æ— ':  
        response_parts.append("- Ergonomically designed for comfort")  
        response_parts.append("- Proper back support angle")  
    
    adjustable_height = tags_dict.get('é«˜åº¦å¯è°ƒèŠ‚æ€§', '')  
    if adjustable_height and adjustable_height != 'æ— ':  
        response_parts.append("- Height adjustable mechanism")  
    
    adjustable_angle = tags_dict.get('è§’åº¦å¯è°ƒèŠ‚æ€§', '')  
    if adjustable_angle and adjustable_angle != 'æ— ':  
        response_parts.append("- Adjustable backrest angle")  
    
    foldable = tags_dict.get('æŠ˜å æ€§', '')  
    if foldable and foldable != 'æ— ':  
        response_parts.append("- Foldable design for storage")  
    
    # å°ºå¯¸å»ºè®®  
    response_parts.append("\n**Dimensions:**")  
    response_parts.append("- Seat height: 45cm from ground")  
    response_parts.append("- Seat depth: 40cm")  
    response_parts.append("- Seat width: 45cm")  
    response_parts.append("- Backrest height: 35cm above seat")  
    
    # åŸºäºæè¿°çš„ç‰¹æ®Šè€ƒè™‘  
    desc_lower = description.lower()  
    if 'dining' in desc_lower:  
        response_parts.append("\n**Dining Chair Specifics:**")  
        response_parts.append("- Standard dining height")  
        response_parts.append("- Easy to move and stack")  
        response_parts.append("- Matches dining table aesthetics")  
    
    elif 'office' in desc_lower:  
        response_parts.append("\n**Office Chair Specifics:**")  
        response_parts.append("- Swivel base for mobility")  
        response_parts.append("- Suitable for desk work")  
        response_parts.append("- Professional appearance")  
    
    elif 'lounge' in desc_lower or 'relax' in desc_lower:  
        response_parts.append("\n**Lounge Chair Specifics:**")  
        response_parts.append("- Lower, more relaxed seating position")  
        response_parts.append("- Wider seat for comfort")  
        response_parts.append("- Emphasis on relaxation")  
    
    # æœ€ç»ˆæ€»ç»“  
    response_parts.append("\n**Design Summary:**")  
    response_parts.append(f"This chair combines {material.lower() if material else 'quality materials'} with "  
                         f"{'minimalist aesthetics' if 'æç®€ä¸»ä¹‰' in style else 'functional design'} "  
                         f"to create a {'versatile' if not tags_dict else 'specialized'} seating solution.")  
    
    return " ".join(response_parts)  

def train_natural_language():  
    """ä½¿ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œè®­ç»ƒ"""  
    print("ğŸ—£ï¸ è‡ªç„¶è¯­è¨€æ¤…å­è®¾è®¡å¾®è°ƒ")  
    print("=" * 50)  
    
    # 1. åŠ è½½æ•°æ®  
    chair_data = load_chair_data_natural()  
    if len(chair_data) == 0:  
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°æ•°æ®")  
        return  
    
    print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬æ•°é‡: {len(chair_data)}")  
    
    # æ˜¾ç¤ºæ ·æœ¬  
    print("\nğŸ“ æ ·æœ¬é¢„è§ˆ:")  
    for i, (prompt, response) in enumerate(chair_data[:2]):  
        print(f"\næ ·æœ¬ {i+1}:")  
        print(f"æç¤º: {prompt}")  
        print(f"å›ç­”: {response[:200]}...")  
    
    # 2. æ£€æŸ¥GPU  
    if not torch.cuda.is_available():  
        print("âŒ GPUä¸å¯ç”¨")  
        return  
    
    device = torch.device("cuda:0")  
    torch.cuda.empty_cache()  
    
    # 3. åŠ è½½æ¨¡å‹  
    print("\nğŸ”„ åŠ è½½æ¨¡å‹...")  
    try:  
        tokenizer = AutoTokenizer.from_pretrained("../models/BlenderLLM", trust_remote_code=True)  
        if tokenizer.pad_token is None:  
            tokenizer.pad_token = tokenizer.eos_token  
        
        model = AutoModelForCausalLM.from_pretrained(  
            "../models/BlenderLLM",  
            trust_remote_code=True,  
            torch_dtype=torch.float16,  
            device_map={"": device},  
            low_cpu_mem_usage=True  
        )  
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")  
        
    except Exception as e:  
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")  
        return  
    
    # 4. è®¾ç½®å¯è®­ç»ƒå‚æ•°  
    print("ğŸ”’ è®¾ç½®å¯è®­ç»ƒå‚æ•°...")  
    for name, param in model.named_parameters():  
        param.requires_grad = False  
        if 'lm_head' in name and 'weight' in name:  
            param.requires_grad = True  
            print(f"  è§£å†»: {name}")  
    
    # 5. ä¼˜åŒ–å™¨  
    optimizer = torch.optim.AdamW(  
        [p for p in model.parameters() if p.requires_grad],  
        lr=1e-6,  # æ›´å°çš„å­¦ä¹ ç‡  
        weight_decay=0.01  
    )  
    
    # 6. è®­ç»ƒ  
    print("\nğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")  
    model.train()  
    
    successful_steps = 0  
    total_loss = 0  
    
    # åªå–å‰20ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒï¼ˆé¿å…è¿‡é•¿ï¼‰  
    train_samples = chair_data[:20]  
    
    for epoch in range(1):  # åªè®­ç»ƒ1ä¸ªepoch  
        print(f"\nğŸ“… Epoch {epoch + 1}/1")  
        
        for i, (prompt, target) in enumerate(train_samples):  
            try:  
                # æ„é€ è®­ç»ƒæ–‡æœ¬ï¼ˆæ›´çŸ­çš„æ ¼å¼ï¼‰  
                text = f"Human: {prompt}\n\nAssistant: {target}"  
                
                # é™åˆ¶é•¿åº¦  
                if len(text) > 1000:  # é™åˆ¶å­—ç¬¦æ•°  
                    text = text[:1000] + "..."  
                
                # Tokenize  
                inputs = tokenizer(  
                    text,  
                    return_tensors="pt",  
                    max_length=256,  # è¾ƒçŸ­çš„åºåˆ—  
                    truncation=True,  
                    padding=True  
                ).to(device)  
                
                # æ£€æŸ¥è¾“å…¥é•¿åº¦  
                if inputs['input_ids'].shape[1] > 256:  
                    print(f"    âš ï¸ æ­¥éª¤ {i+1}: åºåˆ—è¿‡é•¿ï¼Œè·³è¿‡")  
                    continue  
                
                # å‰å‘ä¼ æ’­  
                outputs = model(**inputs, labels=inputs['input_ids'])  
                loss = outputs.loss  
                
                if torch.isnan(loss) or torch.isinf(loss):  
                    print(f"    âš ï¸ æ­¥éª¤ {i+1}: è·³è¿‡æ— æ•ˆæŸå¤±")  
                    continue  
                
                print(f"    ğŸ“ˆ æ­¥éª¤ {i+1}/{len(train_samples)}: æŸå¤± {loss.item():.6f}")  
                
                # åå‘ä¼ æ’­  
                loss.backward()  
                
                # æ¢¯åº¦è£å‰ª  
                torch.nn.utils.clip_grad_norm_(  
                    [p for p in model.parameters() if p.requires_grad],  
                    max_norm=0.5  
                )  
                
                # æ›´æ–°  
                optimizer.step()  
                optimizer.zero_grad()  
                
                successful_steps += 1  
                total_loss += loss.item()  
                
                # æ¸…ç†  
                del loss, outputs, inputs  
                torch.cuda.empty_cache()  
                
            except Exception as e:  
                print(f"    âŒ æ­¥éª¤ {i+1} å¤±è´¥: {e}")  
                optimizer.zero_grad()  
                torch.cuda.empty_cache()  
                continue  
    
    # 7. ä¿å­˜  
    print(f"\nğŸ’¾ ä¿å­˜æ¨¡å‹...")  
    print(f"ğŸ“Š æˆåŠŸè®­ç»ƒæ­¥éª¤: {successful_steps}")  
    
    if successful_steps > 0:  
        print(f"ğŸ“Š å¹³å‡æŸå¤±: {total_loss/successful_steps:.6f}")  
        
        try:  
            output_dir = "./output/natural_language_model"  
            os.makedirs(output_dir, exist_ok=True)  
            
            # åªä¿å­˜å¯è®­ç»ƒå‚æ•°çš„state_dict  
            trainable_params = {}  
            for name, param in model.named_parameters():  
                if param.requires_grad:  
                    trainable_params[name] = param.detach().cpu().clone()  
            
            torch.save(trainable_params, os.path.join(output_dir, "trainable_params.pt"))  
            
            # ä¿å­˜tokenizer  
            tokenizer.save_pretrained(output_dir)  
            
            # ä¿å­˜è®­ç»ƒä¿¡æ¯  
            training_info = {  
                "total_samples": len(chair_data),  
                "trained_samples": len(train_samples),  
                "successful_steps": successful_steps,  
                "average_loss": total_loss/successful_steps,  
                "format": "natural_language"  
            }  
            
            with open(os.path.join(output_dir, "training_info.json"), 'w') as f:  
                json.dump(training_info, f, indent=2)  
            
            print(f"âœ… ä¿å­˜æˆåŠŸ: {output_dir}")  
            
        except Exception as e:  
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")  
    else:  
        print("âŒ æ²¡æœ‰æˆåŠŸçš„è®­ç»ƒæ­¥éª¤")  
    
    print("âœ… è®­ç»ƒå®Œæˆ")  

if __name__ == "__main__":  
    train_natural_language()  
