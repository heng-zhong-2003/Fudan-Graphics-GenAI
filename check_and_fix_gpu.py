#!/usr/bin/env python3  
"""  
GPUè®¾å¤‡æ£€æŸ¥å’Œä¿®å¤è„šæœ¬  
"""  

import torch  
import os  

def check_gpu_status():  
    """æ£€æŸ¥GPUçŠ¶æ€"""  
    print("ğŸ” GPU Status Check")  
    print("=" * 40)  
    
    if not torch.cuda.is_available():  
        print("âŒ CUDA not available")  
        return False  
    
    gpu_count = torch.cuda.device_count()  
    print(f"ğŸš€ Found {gpu_count} GPU(s)")  
    
    for i in range(gpu_count):  
        props = torch.cuda.get_device_properties(i)  
        memory_gb = props.total_memory / 1e9  
        print(f"   GPU {i}: {props.name} ({memory_gb:.1f} GB)")  
    
    current_device = torch.cuda.current_device()  
    print(f"ğŸ“ Current device: cuda:{current_device}")  
    
    return True  

def set_single_gpu():  
    """è®¾ç½®ä½¿ç”¨å•ä¸ªGPU"""  
    if torch.cuda.is_available():  
        # è®¾ç½®åªä½¿ç”¨ç¬¬ä¸€ä¸ªGPU  
        torch.cuda.set_device(0)  
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"  
        print("âœ… Set to use only GPU 0")  
        return True  
    return False  

def test_tensor_operations():  
    """æµ‹è¯•tensoræ“ä½œ"""  
    print("\nğŸ§ª Testing tensor operations...")  
    
    if not torch.cuda.is_available():  
        print("âš ï¸  Using CPU")  
        device = torch.device("cpu")  
    else:  
        device = torch.device("cuda:0")  
        print(f"âœ… Using {device}")  
    
    try:  
        # åˆ›å»ºæµ‹è¯•tensor  
        a = torch.randn(10, 10).to(device)  
        b = torch.randn(10, 10).to(device)  
        c = torch.matmul(a, b)  
        
        print(f"   Tensor device: {a.device}")  
        print(f"   Operation successful: {c.shape}")  
        return True  
        
    except Exception as e:  
        print(f"âŒ Tensor operation failed: {e}")  
        return False  

if __name__ == "__main__":  
    check_gpu_status()  
    set_single_gpu()  
    test_tensor_operations()  
