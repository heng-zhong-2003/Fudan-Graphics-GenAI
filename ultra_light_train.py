#!/usr/bin/env python3  
"""  
è¶…è½»é‡çº§æ¤…å­é£æ ¼ç”Ÿæˆæ¨¡å‹è®­ç»ƒè„šæœ¬  
"""  

import argparse  
import json  
import os  
from pathlib import Path  
import torch  
import gc  
from simple_fine_tune_v2 import MemoryOptimizedBlenderLLMFineTuner  

def clear_memory():  
    """æ¸…ç†GPUå†…å­˜"""  
    gc.collect()  
    torch.cuda.empty_cache()  
    if torch.cuda.is_available():  
        free, total = torch.cuda.mem_get_info()  
        print(f"ğŸ§¹ GPU memory: {free/1e9:.1f}GB free / {total/1e9:.1f}GB total")  

def main():  
    parser = argparse.ArgumentParser(description='Ultra Light Chair Training')  
    parser.add_argument('--data_path', type=str, required=True)  
    parser.add_argument('--base_model', type=str, required=True)  
    parser.add_argument('--output_dir', type=str, default='./output/ultra_light_model')  
    parser.add_argument('--epochs', type=int, default=1)  
    parser.add_argument('--batch_size', type=int, default=1)  
    parser.add_argument('--learning_rate', type=float, default=5e-6)  # æ›´å°çš„å­¦ä¹ ç‡  
    parser.add_argument('--max_length', type=int, default=128)  # å¤§å¹…å‡å°‘åºåˆ—é•¿åº¦  
    
    args = parser.parse_args()  
    
    print("ğŸª‘ Starting Ultra Light Chair Training...")  
    print(f"ğŸ“Š Data: {args.data_path}")  
    print(f"ğŸ¤– Model: {args.base_model}")  
    print(f"ğŸ“ Output: {args.output_dir}")  
    print(f"âš¡ Max length: {args.max_length} (ultra light)")  
    print(f"ğŸ“š Learning rate: {args.learning_rate}")  
    
    # è®¾ç½®å†…å­˜ä¼˜åŒ–ç¯å¢ƒå˜é‡  
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"  
    os.environ["CUDA_LAUNCH_BLOCKING"] = "1"  # æ›´å¥½çš„é”™è¯¯è¿½è¸ª  
    
    device = "cuda:0" if torch.cuda.is_available() else "cpu"  
    print(f"ğŸ¯ Device: {device}")  
    
    clear_memory()  
    
    if not Path(args.data_path).exists():  
        print(f"âŒ Data file not found: {args.data_path}")  
        return  
    
    if not Path(args.base_model).exists():  
        print(f"âŒ Model path not found: {args.base_model}")  
        return  
    
    try:  
        print("ï¿½ï¿½ Creating ultra light fine-tuner...")  
        fine_tuner = MemoryOptimizedBlenderLLMFineTuner(args.base_model, device=device)  
        
        print("ğŸ”„ Loading model...")  
        fine_tuner.load_model()  
        clear_memory()  
        
        print("ğŸ“š Creating mini dataset...")  
        dataset = fine_tuner.create_dataset(args.data_path, args.max_length)  
        
        if len(dataset) == 0:  
            print("âŒ Dataset is empty!")  
            return  
        
        print(f"âœ… Dataset: {len(dataset)} samples")  
        clear_memory()  
        
        print("ğŸ‹ï¸ Starting ultra light training...")  
        model_path = fine_tuner.train(  
            dataset=dataset,  
            output_dir=args.output_dir,  
            epochs=args.epochs,  
            batch_size=args.batch_size,  
            learning_rate=args.learning_rate,  
            warmup_steps=10,  # æœ€å°‘çš„warmup  
            logging_steps=100,  
            save_steps=500,  
            fp16=True,  
            gradient_accumulation_steps=8,  # å¤§æ¢¯åº¦ç´¯ç§¯  
            max_grad_norm=0.5,  # æ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ª  
        )  
        
        print(f"ğŸ‰ Training completed!")  
        print(f"ğŸ’¾ Model saved to: {model_path}")  
        
        clear_memory()  
        
        print("ğŸ§ª Quick test...")  
        try:  
            result = fine_tuner.generate("Design a simple chair:", max_length=100)  
            print(f"ğŸ“ Test result: {result[:80]}...")  
        except Exception as e:  
            print(f"âš ï¸  Test failed: {e}")  
        
    except Exception as e:  
        print(f"âŒ Training failed: {e}")  
        clear_memory()  
        import traceback  
        traceback.print_exc()  
        return  
    
    clear_memory()  
    print("âœ… All done!")  

if __name__ == '__main__':  
    main()  
